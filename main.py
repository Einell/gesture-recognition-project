import cv2
import mediapipe as mp
import time
import numpy as np
import joblib
import threading
from collections import deque
from tensorflow.keras.models import load_model

# å¼•å…¥ä½ çš„æ§åˆ¶è„šæœ¬
import gesture_control as control
import mouse_controller as mc

# ================= é…ç½®åŒºåŸŸ =================
CAMERA_WIDTH, CAMERA_HEIGHT = 640, 400

# --- é™æ€æ¨¡å‹ (SVM) é…ç½® ---
SVM_MODEL_PATH = 'gesture_svm_model.pkl'
SVM_PROB_THRESHOLD = 0.7
SVM_STABILITY_FRAMES = 5
# ğŸ’¡ æ ¸å¿ƒæ”¹åŠ¨ï¼šå®šä¹‰ "ç§»åŠ¨å‹" é™æ€æ‰‹åŠ¿ï¼Œå®ƒä»¬åœ¨æ‰§è¡Œæ—¶æ‰‹è…•ä¼šç§»åŠ¨ï¼Œä½†ä»å±äºé™æ€æ¨¡å¼ã€‚
STATIC_CONTINUOUS_GESTURES = {'right_mouse', 'right_mouse_roll', 'volume_control'}

# --- åŠ¨æ€æ¨¡å‹ (LSTM) é…ç½® ---
LSTM_MODEL_PATH = 'gesture_lstm_model.keras'
LSTM_CLASSES_PATH = 'lstm_classes.npy'
LSTM_SEQ_LENGTH = 20
LSTM_PROB_THRESHOLD = 0.8
LSTM_COOLDOWN = 1.0

# --- è¿åŠ¨æ£€æµ‹é…ç½® ---
MOVEMENT_BUFFER_SIZE = 10
# ğŸ’¡ é˜ˆå€¼è°ƒé«˜ï¼šç•¥å¾®é™ä½çµæ•åº¦ï¼Œè®©é¼ æ ‡æ“ä½œæ›´éš¾è§¦å‘åŠ¨æ€æ¨¡å¼
MOVEMENT_THRESHOLD = 0.015


# ================= æ ¸å¿ƒå·¥å…·ç±» =================

class HandMotionDetector:
    """æ‰‹è…•è¿åŠ¨æ£€æµ‹å™¨"""

    def __init__(self, buffer_size=10, threshold=0.015):
        self.buffer_size = buffer_size
        self.threshold = threshold
        self.histories = {'Left': deque(maxlen=buffer_size), 'Right': deque(maxlen=buffer_size)}

    def update(self, landmarks, label):
        """æ›´æ–°æ‰‹è…•åæ ‡"""
        # æ³¨æ„ï¼šè¿™é‡Œçš„landmarksæ˜¯å¹³æ»‘åçš„
        wrist = landmarks.landmark[0]
        self.histories[label].append([wrist.x, wrist.y])

    def is_moving_violently(self):
        """æ£€æŸ¥æ˜¯å¦æœ‰ä»»æ„ä¸€åªæ‰‹åœ¨å‰§çƒˆè¿åŠ¨"""
        for label, history in self.histories.items():
            if len(history) < self.buffer_size: continue

            # è®¡ç®—æ ‡å‡†å·® (Standard Deviation)
            std = np.std(np.array(history), axis=0)
            avg_std = np.mean(std)

            if avg_std > self.threshold:
                return True
        return False

    def reset_history(self, label):
        if label in self.histories: self.histories[label].clear()


class AsyncExecutor:
    """çº¿ç¨‹æ‰§è¡Œå™¨ï¼šé˜²æ­¢æ§åˆ¶åŠ¨ä½œå¡é¡¿è§†é¢‘æµ"""

    def __init__(self):
        self.running = False
        self.lock = threading.Lock()

    def run(self, func, args):
        if not self.running:
            t = threading.Thread(target=self._task, args=(func, args))
            t.daemon = True
            t.start()

    def _task(self, func, args):
        with self.lock:
            self.running = True
        try:
            func(*args)
        except Exception as e:
            print(f"Action Error: {e}")
        finally:
            with self.lock:
                self.running = False


# ğŸ’¡ æ–°å¢ï¼šæ‰‹åŠ¿å¹³æ»‘æ»¤æ³¢ç±»
class HandSmoother:
    """å¹³æ»‘æ»¤æ³¢ç±»ï¼Œå‡å°‘å…³é”®ç‚¹æŠ–åŠ¨"""

    def __init__(self, alpha=0.6):
        self.alpha = alpha
        self.prev_landmarks = {'Left': None, 'Right': None}

        # ğŸ’¡ ä¿®å¤ç‚¹ï¼šä½¿ç”¨ try-except å—ä» MediaPipe çš„å†…éƒ¨è·¯å¾„å¯¼å…¥ NormalizedLandmarkList
        try:
            # å°è¯• MediaPipe å®˜æ–¹æ–‡æ¡£æ¨èçš„å¸¸è§è·¯å¾„
            from mediapipe.framework.formats import landmark_pb2
            self.NormalizedLandmarkList = landmark_pb2.NormalizedLandmarkList
        except ImportError:
            try:
                # å°è¯• Python å°è£…çš„è·¯å¾„
                from mediapipe.python.framework.formats import landmark_pb2
                self.NormalizedLandmarkList = landmark_pb2.NormalizedLandmarkList
            except ImportError as e:
                # å¦‚æœæ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼Œåˆ™æŠ›å‡ºé”™è¯¯ï¼ŒæŒ‡å¯¼ç”¨æˆ·æ£€æŸ¥ MediaPipe ç‰ˆæœ¬
                print(f"âŒ ä¸¥é‡é”™è¯¯ï¼šæ— æ³•å¯¼å…¥ NormalizedLandmarkList ç»“æ„ã€‚")
                print("è¯·ç¡®ä¿ MediaPipe ç‰ˆæœ¬åœ¨ 0.8.x åˆ° 0.10.x ä¹‹é—´ï¼Œå¹¶å°è¯•é‡æ–°å®‰è£…ã€‚")
                raise ImportError(f"æ— æ³•æ‰¾åˆ° NormalizedLandmarkList: {e}")

    def smooth(self, current_landmarks_proto, label):
        current_data = np.array([[lm.x, lm.y, lm.z] for lm in current_landmarks_proto.landmark])

        if self.prev_landmarks[label] is None:
            self.prev_landmarks[label] = current_data
            return current_landmarks_proto

        # æŒ‡æ•°ç§»åŠ¨å¹³å‡ (EMA)
        smoothed_data = self.alpha * current_data + (1 - self.alpha) * self.prev_landmarks[label]
        self.prev_landmarks[label] = smoothed_data

        # å†™å…¥æ–°çš„landmarks proto
        # ä¿®å¤ç‚¹ï¼šä½¿ç”¨ self.NormalizedLandmarkList å®ä¾‹åŒ–å¯¹è±¡
        smoothed_landmarks_proto = self.NormalizedLandmarkList()
        for i in range(len(current_landmarks_proto.landmark)):
            landmark = smoothed_landmarks_proto.landmark.add()
            landmark.x = smoothed_data[i, 0]
            landmark.y = smoothed_data[i, 1]
            landmark.z = smoothed_data[i, 2]

        return smoothed_landmarks_proto



# ================= ç‰¹å¾æå– (ä¿æŒä¸æ¨¡å‹è®­ç»ƒä¸€è‡´) =================

def get_svm_features(hand_landmarks):
    """SVM å•æ‰‹ç‰¹å¾æå– (63ç»´)"""
    # hand_landmarks å·²ç»æ˜¯å¹³æ»‘åçš„ NormalizedLandmarkList
    lm = np.array([[l.x, l.y, l.z] for l in hand_landmarks.landmark])
    lm = lm - lm[0]
    max_dist = np.max(np.linalg.norm(lm, axis=1))
    if max_dist > 0: lm /= max_dist
    return lm.flatten().reshape(1, -1)


def get_lstm_features(results):
    """LSTM å…¨å±€ç‰¹å¾æå– (126ç»´): [å·¦æ‰‹63ç»´, å³æ‰‹63ç»´]"""
    # results ä¸­çš„ multi_hand_landmarks å·²ç»è¢«æ›¿æ¢ä¸ºå¹³æ»‘åçš„æ•°æ®
    feats = np.zeros(126)

    if results.multi_hand_landmarks:
        for idx, landmarks in enumerate(results.multi_hand_landmarks):
            # æ³¨æ„ï¼šresults.multi_handedness[idx].classification[0].label ä»ç„¶æ˜¯æ­£ç¡®çš„
            label = results.multi_handedness[idx].classification[0].label

            lm = np.array([[l.x, l.y, l.z] for l in landmarks.landmark])
            lm = lm - lm[0]
            max_dist = np.max(np.linalg.norm(lm, axis=1))
            if max_dist > 0: lm /= max_dist

            flat = lm.flatten()

            if label == 'Left':
                feats[0:63] = flat
            elif label == 'Right':
                feats[63:126] = flat

    return feats


# ================= ä¸»ç¨‹åº =================

def main():
    # 1. åŠ è½½æ¨¡å‹
    print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
    try:
        svm_model = joblib.load(SVM_MODEL_PATH)
        lstm_model = load_model(LSTM_MODEL_PATH)
        lstm_classes = np.load(LSTM_CLASSES_PATH, allow_pickle=True)
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæ¯•ã€‚\nSVMç±»åˆ«: {svm_model.classes_}\nLSTMç±»åˆ«: {lstm_classes}")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return

    # 2. åˆå§‹åŒ– MediaPipe
    mp_hands = mp.solutions.hands
    hands = mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.7, min_tracking_confidence=0.6)
    mp_draw = mp.solutions.drawing_utils

    # 3. çŠ¶æ€å˜é‡
    motion_detector = HandMotionDetector(threshold=MOVEMENT_THRESHOLD)
    executor = AsyncExecutor()
    hand_smoother = HandSmoother(alpha=0.6)  # ğŸ’¡ åˆå§‹åŒ–å¹³æ»‘å™¨

    lstm_seq = []
    last_lstm_time = 0
    prev_time = 0  # ğŸ’¡ FPS è®¡æ—¶

    svm_state = {
        'Left': {'cmd': None, 'count': 0},
        'Right': {'cmd': None, 'count': 0}
    }

    cap = cv2.VideoCapture(0)
    cap.set(3, CAMERA_WIDTH)
    cap.set(4, CAMERA_HEIGHT)
    frame_r = mc.MOUSE_CONTROLLER.frameR

    while True:
        # ğŸ’¡ FPS è®¡ç®—å¼€å§‹
        current_time = time.time()
        fps = 1 / (current_time - prev_time) if (current_time - prev_time) > 0 else 0
        prev_time = current_time
        # ğŸ’¡ FPS è®¡ç®—ç»“æŸ

        ret, frame = cap.read()
        if not ret: break

        frame = cv2.flip(frame, 1)
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = hands.process(rgb)

        # UI åŸºç¡€ç»˜åˆ¶
        cv2.rectangle(frame, (frame_r, frame_r), (CAMERA_WIDTH - frame_r, CAMERA_HEIGHT - frame_r), (255, 0, 255), 2)
        cv2.rectangle(frame, (0, 0), (CAMERA_WIDTH, 80), (0, 0, 0), -1)

        mode = "NO HAND"
        # ğŸ’¡ å­˜å‚¨è¦æ˜¾ç¤ºçš„æ–‡æœ¬å’Œé¢œè‰²ï¼Œç”¨äºé«˜äº®
        display_results = []

        # æ¨¡å¼åˆ‡æ¢æ ‡å¿—
        force_static_lock = False

        if results.multi_hand_landmarks:
            # ğŸ’¡ æ­¥éª¤ 1: å¹³æ»‘æ‰‹éƒ¨å…³é”®ç‚¹å¹¶æ›¿æ¢ results ä¸­çš„æ•°æ®
            smoothed_landmarks = []
            for idx, hand_lms in enumerate(results.multi_hand_landmarks):
                lbl = results.multi_handedness[idx].classification[0].label
                # å¯¹å½“å‰æ‰‹éƒ¨å…³é”®ç‚¹è¿›è¡Œå¹³æ»‘
                smoothed_lms = hand_smoother.smooth(hand_lms, lbl)
                smoothed_landmarks.append(smoothed_lms)
                # è¿åŠ¨æ£€æµ‹ä½¿ç”¨å¹³æ»‘åçš„å…³é”®ç‚¹
                motion_detector.update(smoothed_lms, lbl)
                # ç»˜åˆ¶å¹³æ»‘åçš„éª¨æ¶
                mp_draw.draw_landmarks(frame, smoothed_lms, mp_hands.HAND_CONNECTIONS)

            # æ›¿æ¢åŸå§‹ç»“æœï¼Œç¡®ä¿åç»­æ­¥éª¤ä½¿ç”¨å¹³æ»‘åçš„æ•°æ®
            results.multi_hand_landmarks = smoothed_landmarks
            # ----------------------------------------------------------------------
            # æ­¥éª¤ 2: ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦æœ‰ "ç§»åŠ¨å‹" é™æ€æ‰‹åŠ¿ (å¦‚é¼ æ ‡æ§åˆ¶)ï¼Œå¦‚æœæœ‰åˆ™å¼ºåˆ¶é”å®š STATIC
            # ----------------------------------------------------------------------

            for idx, hand_lms in enumerate(results.multi_hand_landmarks):
                lbl = results.multi_handedness[idx].classification[0].label
                feats = get_svm_features(hand_lms)
                probs = svm_model.predict_proba(feats)[0]
                best_idx = np.argmax(probs)
                conf = probs[best_idx]
                gesture = svm_model.classes_[best_idx]

                # é»˜è®¤æ˜¾ç¤ºé¢œè‰²ä¸ºç™½è‰²
                text_color = (255, 255, 255)
                # æ£€æŸ¥æ˜¯å¦ä¸ºé«˜ç½®ä¿¡åº¦çš„è¿ç»­ç§»åŠ¨å‹æ‰‹åŠ¿
                if gesture in STATIC_CONTINUOUS_GESTURES and conf > SVM_PROB_THRESHOLD:
                    # å‘ç°é¼ æ ‡æ§åˆ¶æ‰‹åŠ¿ï¼Œå¼ºåˆ¶é”å®šä¸º STATICï¼Œå¹¶ç«‹å³æ‰§è¡Œ
                    force_static_lock = True
                    # ğŸ’¡ æ‰§è¡Œæ—¶é«˜äº®
                    text_color = (0, 255, 255)  # é’è‰²é«˜äº®
                    control.execute_gesture_action(gesture, cap, frame, hand_lms)
                    # å®æ—¶æ‰‹åŠ¿ä¸èµ°é˜²æŠ–é€»è¾‘ï¼Œä½†éœ€è¦æ›´æ–°çŠ¶æ€
                    svm_state[lbl]['cmd'] = gesture
                    svm_state[lbl]['count'] = 0

                # å¿…é¡»æŠŠè¯†åˆ«ç»“æœå’Œé¢œè‰²ä¹Ÿå­˜èµ·æ¥
                display_results.append({
                    'text': f"{lbl}: {gesture} ({conf:.0%}) {'[LOCK]' if force_static_lock else ''}",
                    'color': text_color
                })

            # ----------------------------------------------------------------------
            # æ­¥éª¤ 3: æœ€ç»ˆæ¨¡å¼åˆ¤å®š
            # ----------------------------------------------------------------------

            is_moving_violently = motion_detector.is_moving_violently()

            if force_static_lock:
                # é”å®šæ¨¡å¼ä¼˜å…ˆçº§æœ€é«˜
                mode = 'STATIC (LOCKED)'
            elif is_moving_violently:
                mode = 'DYNAMIC'
            else:
                mode = 'STATIC'

            # ----------------------------------------------------------------------
            # æ­¥éª¤ 4: åˆ†æµæ‰§è¡Œ
            # ----------------------------------------------------------------------

            # --- åŠ¨æ€æ¨¡å¼ ---
            if 'DYNAMIC' in mode:
                # ğŸ’¡ æ”¹è¿›ç‚¹ï¼šç»§ç»­æ”¶é›†ç‰¹å¾ï¼Œè®©åºåˆ—å¹³ç¨³è¿‡æ¸¡
                feats = get_lstm_features(results)
                lstm_seq.append(feats)
                lstm_seq = lstm_seq[-LSTM_SEQ_LENGTH:]

                # æ¸…é™¤é™æ€è®¡æ•°å™¨ï¼Œé˜²æ­¢åˆ‡å›æ—¶è¯¯è§¦
                svm_state['Left']['count'] = 0
                svm_state['Right']['count'] = 0

                if len(lstm_seq) == LSTM_SEQ_LENGTH:
                    input_data = np.expand_dims(lstm_seq, axis=0)
                    pred = lstm_model.predict(input_data, verbose=0)[0]
                    best_idx = np.argmax(pred)
                    conf = pred[best_idx]
                    gesture = lstm_classes[best_idx]

                    text_color = (255, 255, 255)  # é»˜è®¤ç™½è‰²

                    if conf > LSTM_PROB_THRESHOLD:
                        if time.time() - last_lstm_time > LSTM_COOLDOWN:
                            if gesture not in ['background', 'static']:
                                print(f"ğŸŒŠ æ‰§è¡ŒåŠ¨æ€: {gesture}")
                                # ğŸ’¡ æ‰§è¡Œæ—¶é«˜äº®
                                text_color = (0, 255, 0)  # ç»¿è‰²é«˜äº®
                                main_hand = results.multi_hand_landmarks[0]
                                executor.run(control.execute_gesture_action, (gesture, cap, frame, main_hand))
                                last_lstm_time = time.time()
                                lstm_seq = []  # è§¦å‘åæ¸…ç©ºåºåˆ—

                    # ç»Ÿä¸€æ·»åŠ æ˜¾ç¤ºç»“æœ
                    display_results.append({
                        'text': f"LSTM: {gesture} ({conf:.0%})",
                        'color': text_color
                    })

            # --- é™æ€æ¨¡å¼ ---
            else:
                # ğŸ’¡ æ”¹è¿›ç‚¹ï¼šç»§ç»­å‘ LSTM åºåˆ—æ·»åŠ é™æ€/èƒŒæ™¯å¸§ï¼Œä¿è¯åºåˆ—å¹³ç¨³
                feats = get_lstm_features(results)
                lstm_seq.append(feats)
                lstm_seq = lstm_seq[-LSTM_SEQ_LENGTH:]

                # éå†æ¯åªæ‰‹ï¼Œç‹¬ç«‹è¯†åˆ«
                for idx, hand_lms in enumerate(results.multi_hand_landmarks):
                    lbl = results.multi_handedness[idx].classification[0].label

                    # å¦‚æœè¿™åªæ‰‹å·²ç»è¢« "LOCK" é€»è¾‘å¤„ç†è¿‡ï¼Œåˆ™è·³è¿‡é‡å¤çš„æ‰§è¡Œé€»è¾‘ï¼Œåªå¤„ç†æ˜¾ç¤º
                    is_locked = (force_static_lock and svm_state[lbl]['cmd'] in STATIC_CONTINUOUS_GESTURES)

                    # é‡æ–°æå–ç‰¹å¾è¿›è¡Œé¢„æµ‹ï¼ˆè¿™æ¬¡æ˜¯ä¸ºäº†è§¦å‘å‹æ‰‹åŠ¿çš„é˜²æŠ–ï¼‰
                    feats = get_svm_features(hand_lms)
                    probs = svm_model.predict_proba(feats)[0]
                    best_idx = np.argmax(probs)
                    conf = probs[best_idx]
                    gesture = svm_model.classes_[best_idx]

                    # æŸ¥æ‰¾è¿™åªæ‰‹çš„æ˜¾ç¤ºç»“æœï¼Œå¹¶æ›´æ–°å…¶é¢œè‰²
                    result_entry = next((item for item in display_results if item['text'].startswith(f"{lbl}:")), None)

                    if not is_locked:
                        if conf > SVM_PROB_THRESHOLD:
                            state = svm_state[lbl]

                            # é€»è¾‘ B: è§¦å‘å‹ (ç‚¹å‡»/æŒ‰é”®) - é˜²æŠ–æ‰§è¡Œ
                            if gesture not in STATIC_CONTINUOUS_GESTURES:
                                if gesture == state['cmd']:
                                    state['count'] += 1
                                    if state['count'] >= SVM_STABILITY_FRAMES:
                                        print(f"ğŸ›‘ æ‰§è¡Œé™æ€: {gesture}")
                                        # ğŸ’¡ æ‰§è¡Œæ—¶é«˜äº®
                                        if result_entry: result_entry['color'] = (255, 0, 0)  # çº¢è‰²é«˜äº®
                                        executor.run(control.execute_gesture_action, (gesture, None, None, hand_lms))
                                        state['count'] = 0
                                else:
                                    state['cmd'] = gesture
                                    state['count'] = 1

                                # ğŸ’¡ æŒç»­é«˜äº®æ­£åœ¨é˜²æŠ–è®¡æ•°çš„æ‰‹åŠ¿
                                if state['count'] > 0 and result_entry:
                                    result_entry['color'] = (255, 165, 0)  # æ©™è‰²è¡¨ç¤ºè®¡æ•°ä¸­
                            else:
                                # ç¡®ä¿éè§¦å‘å‹æ‰‹åŠ¿åœ¨é LOCK çŠ¶æ€ä¸‹ä¸å½±å“è®¡æ•°å™¨
                                state['count'] = 0
                                state['cmd'] = gesture
                        else:
                            svm_state[lbl]['count'] = 0

                    # å¦‚æœæ²¡æœ‰è¢« LOCK é€»è¾‘æ˜¾ç¤ºï¼Œä¸” result_entry å°šæœªå­˜åœ¨ï¼Œåˆ™æ·»åŠ 
                    if not result_entry:
                        display_results.append({
                            'text': f"{lbl}: {gesture} ({conf:.0%})",
                            'color': (255, 255, 255)
                        })
                    # å¦‚æœæ˜¯ Lock é€»è¾‘æ·»åŠ çš„ï¼Œä½†ç½®ä¿¡åº¦ä½äºé˜ˆå€¼ï¼Œåˆ™å»æ‰ LOCK æ ‡å¿—
                    elif is_locked and conf <= SVM_PROB_THRESHOLD:
                        result_entry['text'] = result_entry['text'].replace(' [LOCK]', '')
                        result_entry['color'] = (255, 255, 255)  # æ¢å¤ç™½è‰²


        else:
            # æ— æ‰‹æ—¶æ¸…ç©ºçŠ¶æ€
            lstm_seq = []
            motion_detector.histories['Left'].clear()
            motion_detector.histories['Right'].clear()
            hand_smoother.prev_landmarks['Left'] = None  # ğŸ’¡ æ¸…ç©ºå¹³æ»‘å™¨çŠ¶æ€
            hand_smoother.prev_landmarks['Right'] = None  # ğŸ’¡ æ¸…ç©ºå¹³æ»‘å™¨çŠ¶æ€

        # ================= UI æ˜¾ç¤º =================
        # æ˜¾ç¤ºæ¨¡å¼çŠ¶æ€
        color = (0, 255, 0) if 'STATIC' in mode else (0, 165, 255)
        if mode == 'NO HAND': color = (0, 0, 255)
        cv2.putText(frame, f"MODE: {mode}", (10, 50), cv2.FONT_HERSHEY_DUPLEX, 1, color, 2)

        # ğŸ’¡ æ˜¾ç¤º FPS åœ¨å³ä¸Šè§’
        fps_text = f"FPS: {int(fps)}"
        fps_size, _ = cv2.getTextSize(fps_text, cv2.FONT_HERSHEY_DUPLEX, 1, 2)
        cv2.putText(frame, fps_text, (CAMERA_WIDTH - fps_size[0] - 10, 50), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 255, 0),
                    2)

        # æ˜¾ç¤ºè¯†åˆ«ç»“æœå’Œæ¦‚ç‡ (ä½¿ç”¨æ–°çš„ display_results)
        y = 50
        for item in display_results:
            cv2.putText(frame, item['text'], (400, y), cv2.FONT_HERSHEY_PLAIN, 2, item['color'], 2)
            y += 30

        cv2.imshow('Merged Gesture System', frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()
    hands.close()


if __name__ == "__main__":
    main()